# What are containers?

## What are containers?

- Consistent, reproducible environments.
- Bundles of code, libraries, and dependencies.
- Secure environments separated from data on the host system.

```{r}
#| fig-cap: "Illustration of a container isolating software on a host (Source: Kevin Rue)."
knitr::include_graphics("img/containers-draft-02-slide-04.svg")
```

## Multiple containers isolate software on a single host

```{r}
#| fig-cap: "Illustration of multiple containers on a single host (Source: Kevin Rue)."
knitr::include_graphics("img/containers-draft-02-slide-05.svg")
```

## Reproducible Research

### Containers

- Contain all code dependencies including operating system dependencies.
- Can reproduce the exact same environment on different host operating systems.

### For comparison

- [Conda](https://anaconda.org/anaconda/conda) only reproduces installed software
  but has different sets of dependencies for different operating systems.

# Using Containers

## Containers Engines

### Docker

- One of the first and most famous.
- **Caveat:** requires administrator permissions to run.

### Singularity

- Gained popularity over Docker thanks to the absence of administrator requirement.

### Apptainer

- A fork of Singularity.
  Chosen for JADE cluster and OBDS server.

## Containers: Images and Definition Files

### Image Files

Container images use the `*.sif` file extension.

- Those are the files that contain the actual data.

### Definition Files

Container definitions use the `*.def` extension.

- Those are scripts that describe the container and were used to create the corresponding image files.

::: {.callout-note}
In this lesson, we will initially use existing images to run commands before writing our own definitions and creating our own images.
:::

## Containers on JADE

The IT team of the JADE cluster prepared a small set of containers that can help you get started.

They can be found in the directory `/package/containers/`.

```
/package/containers/
│
├── centos          # CentOS container, mimics previous cluster
├── ubuntu          # Basic Ubuntu container, mimics JADE
├── R-4.3.0         # Ubuntu + R 4.3.0
├── rstudio-server  # R 4.3.0 + RStudio Server
├── miniforge       # Ubuntu + Miniforge
└── builder         # Ubuntu + compilers & libraries
```

## Containers on OBDS

On OBDS, we replicated some of those containers (and more) in preparation for the exercises.

They can be found in the directory `/project/shared/resources/containers/`.


```
/project/shared/resources/containers/
├── builder
│   ├── builder.def
│   └── builder.sif
├── fastqc
│   ├── fastqc.def
│   └── fastqc.sif
├── miniforge
│   ├── miniforge.def
│   └── miniforge.sif
├── samtools
│   ├── samtools.def
│   └── samtools.sif
└── ubuntu-22
    ├── ubuntu-22.def
    └── ubuntu-22.sif
```

## Using Containers

Given a container file, Apptainer commands can execute commands in the container in various ways.

For instance, the following commands both launch a Bash shell within the given container.

### shell

The `shell` sub-command specifically opens an interactive shell in the given container:

```bash
apptainer shell /project/shared/resources/containers/ubuntu-22/ubuntu-22.sif
```

### exec

The `exec` sub-command execute any given command in the given container:

```bash
apptainer exec /project/shared/resources/containers/ubuntu-22/ubuntu-22.sif bash
```

::: {.callout-note}
In practice, both can provide a Bash shell, but `shell` is explicitly intended for interactive use, while `exec` is more suited for single-command execution
:::

## Support for Docker Images

Apptainer can also run Docker images from online repositories.

```bash
apptainer exec docker://ubuntu:22.04 bash
```

Apptainer caches downloaded containers to the user’s home directory.

To avoid quota issues, change the cache location in your `.bash_aliases`.

```bash
export APPTAINER_CACHEDIR=/project/example/myname/mycontainers
```

## Accessing Data on the Host System

Containers mainly provide software.

Containers must be given controlled access to the host system for:

- Accessing input data files
- Storing output data files

Access to specific directories is given by 'mounting' (also known as 'binding') the relevant directories on the host system to specific paths accessible from within the container.

## Mounting (or Binding)

### Example

```bash
apptainer exec -B /project/shared/resources /project/shared/resources/containers/ubuntu-22/ubuntu-22.sif bash 
```

- The `-B` option 'binds' a directory to the container.
- By default, containers can read and write to bounds directories,
  unless ‘read-only’ is specified^[<https://apptainer.org/docs/user/main/bind_paths_and_mounts.html>].
- Multiple directories can be bound to the same container, repeating the `-B` option as many times as necessary.

```bash
apptainer exec \
  -B /project/shared/resources \
  -B /project/$USER \
  /project/shared/resources/containers/ubuntu-22/ubuntu-22.sif bash 
```

## Exercise

In the container: `r-4.3.0.sif`

Execute the command:

```bash
R --version
```

### Hints

- Use the `apptainer exec` command.

## Exercise

In the container: `r-4.3.0.sif`

Execute the R script: `installed_packages.R`

### Hints

- Use the Bash command `Rscript`
- The full command should look like `Rscript /path/to/installed_packages.R`.
- The directory that contains the R script must be bound to the container,
  to be visible from inside the container.

## Exercise

In the Docker container accessible online:

```
bioconductor/bioconductor_docker:devel
```

Execute the R script: `installed_packages.R`

### Hints

- Before you run the `apptainer exec` command,
  make sure that the environment variable `APPTAINER_CACHEDIR` is set in your Bash session.
- The first time you run an `apptainer exec` command on a new remote container,
  the command will likely take a minute or two to download the container files.
  If you see messages like "Copying blob" and "info unpack layer",
  you are on the right track, keep waiting!

Visually compare the output (R version, list of packages) with the previous exercise.

## Exercise

In the container: `fastqc.sif`

Run the FastQC program on the input file `ERR1755082_1.fastq.gz`,
and direct the output to your own project directory.

### Hints

- In the container, the `fastqc` command is already on the PATH.
- The input file `ERR1755082_1.fastq.gz` is stored in the shared resources, next to the container file.
- For tidiness, manually create a subdirectory in your project directory,
  and pass the path to this directory to the `fastqc` command.
- The full command should look like `fastqc -o /path/to/output /path/to/input`.
- Remember to bind input and output directories to the container.

# Creating Containers

## Creating containers

Step 1: Write a definition file.

A definition file generally refers to an existing image to use as a basis for the new image.

A definition file is organised into sections^[<https://apptainer.org/docs/user/main/definition_files.html#sections>].

### Key sections

`%help` : message displayed by the run-help command.

`%post` : commands to modify the container (e.g., download files, install software, create directories).

`%environment` : define environment variables.

## Example Definition File

```yaml
bootstrap: localimage
From: /project/shared/resources/containers/miniforge.sif

%help
 Miniforge 24.3.0-0 (Mamba 1.5.8 + Conda 24.1.2) + FastQC

%environment
 export PATH=/usr/local/mamba/bin:$PATH

%post
 mamba install -q -y -c bioconda fastqc
```

## Header and Bootstrap Agent

The bootstrap agent indicates where the base image should be obtained from^[<https://apptainer.org/docs/user/main/definition_files.html#header>].

In this lesson we use the following agents:

- `docker` , for images hosted online on Docker Hub.

```
bootstrap: docker
From: ubuntu:22.04
```

- `localimage` , for images saved on the teaching server.

```
bootstrap: localimage
From: /project/shared/resources/containers/miniforge.sif
```

## Building a Container

```bash
apptainer build <filename>.sif <filename>.def
```

### Remember

- `*.sif` is used for image files.
- `*.def` is used for definition files.

## Sharing a Container

Image files can be copied, but will only work on systems that have the same CPU architecture.

`r fa("triangle-exclamation")` Faster, with a major caveat.

Definition files can be used to build more copies of the same image on other systems.

`r fa("thumbs-up")` Slower, but CPU compatibility is guaranteed.

::: {.callout-note}
If the definition requires a local base image, you may have to build that one first (and so on).
:::

## Exercise

Using the prepared container definition file: `samtools.def`

First, build an image file called `samtools.sif` in your project directory.

Then, test the image, simply running the command `samtools`.

```yaml
Bootstrap: localimage
From: /storage/olin0164/containers/2024-10/miniforge/miniforge.sif

%post
  export DEBIAN_FRONTEND=noninteractive
  apt update -y ; apt-get clean
  rm -rf /var/lib/apt/lists/*

  mamba init --system  # create /etc/profile.d/conda.sh
  . /etc/profile.d/conda.sh  # init Conda
  mamba create -n my-samtools -c bioconda -c conda-forge samtools -y  # setup your Conda environment

%environment
  export SINGULARITY_SHELL=/bin/bash
  . /etc/profile.d/conda.sh
  conda activate my-samtools  # auto-load your Conda environment
```

## Exercise

Choose a program that you already know how to use.

Write a definition file and create an image that includes that program.

Run a test command to prove that the program is successfully installed in the container.

::: {style="text-align: center;"}
**Free for all!**
:::

# Interactive Applications Containerised

## RStudio Server in a Container

On OBDS and JADE, the standard RStudio server restricts memory allowance in interactive sessions for fair usage between users on login nodes.

As an alternative, a container image that contains RStudio server can be run as a job on a compute node of JADE, or directly on the OBDS login node.

The process is not straightforward but documented at <https://lumin.imm.ox.ac.uk/R-cbrg/#rstudio-container>.

In this lesson, we follow those instructions, adapted to the OBDS server.

## Running an RStudio Server Container on the OBDS Server

```{r}
#| fig-cap: "Illustration of RStudio Server containers on the OBDS server (Source: Kevin Rue)."
knitr::include_graphics("img/containers-draft-02-slide-29.svg")
```

## What the RStudio Server Container Does

The container runs an instance of RStudio server on a port specific to each user.

### How?

- On UNIX system, user IDs are numbers.
- The container uses the ID of the user running the container to calculate a unique port number within an acceptable range of values.

### What then?

Step 1. Run an instance of the container as a Slurm job.

Step 2. While the container is running, connect to the port that runs your own instance of the RStudio Server.

::: {.callout-note}
Step 2 is not straightforward. We give you a semi-automated script for that.
:::

## Example

### Step 1. Run an instance of the container as a Slurm job

Submitting the job.

```
$ sbatch /project/shared/resources/containers/rstudio-server/rstudio-container.sh
Submitted batch job 107
```

Checking that the job is running.

```
$ squeue --me
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
              1075      long  rstudio olin0164  R      16:29      1 obds
```

Reveal the randomly generated password in the job output file.

```
$ cat slurm-1075.out 
/tmp
Your RStudio password = hFtOzSOPcs1XnZ1PxWP3R0xJ
```

## Example

:::: {.columns}

::: {.column width="50%"}
### Step 2. Connect to the container

```
% bash bin/connect-to-wn-rstudio-obds.sh 
***********************************
* Enter your password if prompted *
***********************************
Querying CCB for your personal SSH port number ...
Querying CCB for your Slurm job running RStudio ...
****************************************
*          CCB RStudio tunnel          *
****************************************
* Creating SSH tunnel:                 *
* your PC -> OBDS                      *
* After connecting, no more feedback   *
* is given so assume successful.       *
* In web browser open:                 *
*                                      *
*      +-----------------------+       *
*      | http://localhost:8888 |       *
*      +-----------------------+       *
*                                      *
****************************************
```
:::

::: {.column width="50%"}
### Step 3. Get to work!

```{r}
#| fig-cap: "Working in the containerised RStudio server (Source: Kevin Rue)."
#| out-width: "100%"
knitr::include_graphics("img/rstudio-container-obds-install.png")
```
:::

::::


## Exercise

### Step 1. Running the RStudio Server Container

For this first part of the process, you must run the following commands **on the OBDS server**.

Change directory to your project directory.

```bash
cd /project/$USER
```

Submit a Slurm job that runs the container.

```bash
sbatch /project/shared/resources/containers/rstudio-server/rstudio-container.sh
```

Check that the job is running.

```bash
squeue --me
```

Display the contents of the job output file (substitute `*` by the job identifier reported by the previous command).

```bash
cat slurm-*.out
```

Make a note of the password displayed by the last command. You will need it in the second part of the process.

## Exercise

### Step 2. Connecting to your RStudio Server Container

This second part of the process takes place **on your own computer** (not on your OBDS account).

Download (from OneDrive) a copy of either script below depending on your operating system.

- Windows: `connect-to-wn-rstudio.bat`
- Linux / macOS: `connect-to-wn-rstudio.sh`

Run the script.

- Windows: double click on the file.
- Linux / macOS: In a terminal, type `bash connect-to-rstudio-server-obds.sh`.

Follow the instructions displayed by the script.

- Type your username when prompted (first time only^[The username will be cached in a file in your home directory for subsequent uses.])
- Open a web browser tab to <http://localhost:8888>
- Log in using you SSO (username) and the random password copied earlier.

## Exercise

### Step 3. Get to work!

Have a play with the RStudio interface. Here are some ideas:

- Check the initial working directory of the R session.
- Check the library path(s).
- Check the list of packages installed.
- Install packages.

Where do packages get installed?
How might that impact the reproducibility of your work?

## Using a Custom Package Library with the RStudio Server Container

Manually create an empty directory that will act as an R library:

```bash
mkdir /project/$USER/my_r_library
```

Make a copy of the `rstudio-container.sh` script.

```bash
cp \
  /project/shared/resources/containers/rstudio-server/rstudio-container.sh \
  /project/$USER/rstudio-container.sh
```

Edit the `apptainer run` to bind the directory of your custom R library.

```bash
apptainer run \
  --writable-tmpfs \
  -B $TMPDIR:/tmp \
  -B /project/$USER/my_r_library \
  /project/shared/resources/containers/rstudio-server/rstudio-server.sif
```

Submit a Slurm job that runs the container using that customised script.

```bash
sbatch /project/$USER/rstudio-container.sh
```

In the Rstudio Server session, set your library path to the same directory.

```r
.libPaths("/project/USERNAME/my_r_library") # edit USERNAME !
```

Install your favourite package(s).

```r
install.packages("BiocManager")
```

## Why Using a Custom R Library?

The packages will be installed in the bound directory (first in the library path).

The directory (and packages) will remain after the container is terminated and can be re-used by other containers.

The same container for RStudio Server can be re-used for multiple projects.

Custom libraries (one or more!) can be plugged to the container when the Slurm job is submitted.

Individual projects can use different libraries.

### Caveat

The R libraries are not part of the container,
and thus reproducibility is not guaranteed if you add, update, or remove
packages from those libraries.

# Summary

## Summary

Containers provide a fixed environment to facilitate reproducible work.

Containers can be shared, locally or online.

New containers can be created, from minimal operating systems or from other containers.

You are encouraged to create and share your own containers:

- You can install any version of any software in your own containers.
- You can ask more disk quota if you run out of storage for containers.

## Further Reading

- [WIMM CCB documentation](https://lumin.imm.ox.ac.uk/containers/) (Requires SSO)
- [Apptainer documentation](https://apptainer.org/documentation/)
- [BMRC documentation](https://www.medsci.ox.ac.uk/for-staff/resources/bmrc/scientific-software-directory)

## References

```{r}
#| results: asis
PrintBibliography(bib)
```
